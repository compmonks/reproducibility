{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO\n",
    "- experiment: p300 speller\n",
    "- stimulation: rsvp 100ms(stim) / 75ms(blank) / 2500ms break between char / 15 flashes per char / random words of 10 chars\n",
    "- users tested: 1\n",
    "- devices tested : \n",
    "    - muse 2: freq 256Hz / channels TP9,AF7,AF8,TP10\n",
    "    - muse 2+: freq 256Hz / channels TP9,AF7,AF8,TP10,POz\n",
    "    - OpenBCI: freq 125Hz / channels FC3,FCz,FC4,T7,C3,Cz,C4,T8,P7,P3,Pz,P4,P8,O1,O2,Oz\n",
    "- metric used : Area Under the Curve (AUC)\n",
    "\n",
    "\n",
    "This code demonstrates the evolution of selected predictors over increasing amount of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILT-IN\n",
    "import os,sys\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "# DATAFRAMES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# SCIKIT-LEARN\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit,GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# PYRIEMANN\n",
    "from pyriemann.estimation import ERPCovariances, XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.classification import MDM\n",
    "from pyriemann.spatialfilters import Xdawn\n",
    "\n",
    "# MNE\n",
    "from mne import Epochs, find_events\n",
    "from mne.channels import read_montage\n",
    "from mne import create_info, concatenate_raws\n",
    "from mne.io import RawArray\n",
    "from mne.decoding import Vectorizer\n",
    "\n",
    "# PLOTTING\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_folder_path = \"../data/p300_speller\" # relative datasets path\n",
    "the_user = \"compmonks\" # check available users in data folder or add new ones\n",
    "the_device = \"muse2+\" # \"muse2+\" # \"muse2\" # \"openbci_v207\" # available devices\n",
    "the_freq = 256 # 256 (Muse) # 125 (OpenBCI) # Sampling Frequency in Hertz\n",
    "break_epoch = 2500 # ms epoch used to break between character sessions\n",
    "the_montage = \"standard_1005\" # \"standard_1005\" (Muse) # \"standard_1020\" (OpenBCI) # channels montage\n",
    "the_units = \"uVolts\" # \"uVolts\" # \"Volts\" # unit of received data from device\n",
    "the_markers = {'Non-Target': 2, 'Target': 1} # markers from stim data\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "diverging_color_palette = \"coolwarm\"\n",
    "categorical_color_palette = \"Paired\"\n",
    "\n",
    "# list of best known discriminators for P300\n",
    "clfs = OrderedDict()\n",
    "clfs['Vect + LR'] = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression())\n",
    "clfs['Vect + RegLDA'] = make_pipeline(Vectorizer(), LDA(shrinkage='auto', solver='eigen'))\n",
    "clfs['Xdawn + RegLDA'] = make_pipeline(Xdawn(2, classes=[1]), Vectorizer(), LDA(shrinkage='auto', solver='eigen'))\n",
    "clfs['ERPCov + TS'] = make_pipeline(ERPCovariances(), TangentSpace(), LogisticRegression())\n",
    "clfs['ERPCov + MDM'] = make_pipeline(ERPCovariances(), MDM())\n",
    "clfs['XdawnCov + TS + LReg'] = make_pipeline(XdawnCovariances(2),TangentSpace(metric='riemann'),LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimatorParamsDict():\n",
    "    \"\"\"# get all params of a list of estimators and return them as a distionary.\"\"\"\n",
    "    \n",
    "    pass\n",
    "#\n",
    "def train_save(self, the_predictor, the_X, the_y):\n",
    "    \"\"\" Train a given predictor formatted as a pipeline.\"\"\"\n",
    "\n",
    "    trained = the_predictor.fit(the_X,the_y)\n",
    "    joblib.dump(trained,'predictor_{}.pkl'.format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:muse2+ user:compmonks dir:['session_003', 'session_004', 'session_002', 'session_000', 'session_001'] session dir:session_003\n",
      "session_num: 0\n",
      "files: ['compmonks_T2_FEEDBACK_2019-5-2_8-16-27-246000.hdf5', 'compmonks_T2_INTERAXON-Muse2_2019-5-2_8-24-15-829809.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=96829\n",
      "    Range : 0 ... 96828 =      0.000 ...   378.234 secs\n",
      "Ready.\n",
      "1798 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: ERPCov + MDM score:0.707277628032345\n",
      "device:muse2+ user:compmonks dir:['session_003', 'session_004', 'session_002', 'session_000', 'session_001'] session dir:session_004\n",
      "session_num: 1\n",
      "files: ['compmonks_T2_INTERAXON-Muse2_2019-5-2_11-6-58-216310.hdf5', 'compmonks_T2_FEEDBACK_2019-5-2_10-59-17-340000.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=96478\n",
      "    Range : 0 ... 96477 =      0.000 ...   376.863 secs\n",
      "Ready.\n",
      "3585 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: XdawnCov + TS + LReg score:0.74629743475102\n",
      "device:muse2+ user:compmonks dir:['session_003', 'session_004', 'session_002', 'session_000', 'session_001'] session dir:session_002\n",
      "session_num: 2\n",
      "files: ['compmonks_T2_INTERAXON-Muse2_2019-4-30_11-19-7-974060.hdf5', 'compmonks_T2_FEEDBACK_2019-4-30_11-11-7-119000.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=96841\n",
      "    Range : 0 ... 96840 =      0.000 ...   378.281 secs\n",
      "Ready.\n",
      "7170 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: ERPCov + MDM score:0.7763366908552656\n",
      "device:muse2+ user:compmonks dir:['session_003', 'session_004', 'session_002', 'session_000', 'session_001'] session dir:session_000\n",
      "session_num: 3\n",
      "files: ['compmonks_T2_FEEDBACK_2019-4-30_10-17-51-247000.hdf5', 'compmonks_T2_INTERAXON-Muse2_2019-4-30_10-25-37-489075.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=96833\n",
      "    Range : 0 ... 96832 =      0.000 ...   378.250 secs\n",
      "Ready.\n",
      "12553 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: Vect + LR score:0.8071430896653072\n",
      "device:muse2+ user:compmonks dir:['session_003', 'session_004', 'session_002', 'session_000', 'session_001'] session dir:session_001\n",
      "session_num: 4\n",
      "files: ['compmonks_T2_FEEDBACK_2019-4-30_10-50-59-952000.hdf5', 'compmonks_T2_INTERAXON-Muse2_2019-4-30_10-58-43-373075.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=96887\n",
      "    Range : 0 ... 96886 =      0.000 ...   378.461 secs\n",
      "Ready.\n",
      "19734 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: Vect + LR score:0.8083000308774301\n",
      "device:muse2+ user:compmonks dir:['session_003', 'session_004', 'session_005', 'session_002', 'session_011', 'session_010', 'session_007', 'session_000', 'session_009', 'session_008', 'session_001', 'session_006', 'session_012', 'session_013', 'session_014'] session dir:session_003\n",
      "session_num: 5\n",
      "files: ['compmonks_T2_INTERAXON-Muse2_2019-6-10_8-5-59-625164.hdf5', 'compmonks_T2_FEEDBACK_2019-6-10_7-58-5-101000.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=96859\n",
      "    Range : 0 ... 96858 =      0.000 ...   378.352 secs\n",
      "Ready.\n",
      "28714 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: Vect + LR score:0.8161158820976591\n",
      "device:muse2+ user:compmonks dir:['session_003', 'session_004', 'session_005', 'session_002', 'session_011', 'session_010', 'session_007', 'session_000', 'session_009', 'session_008', 'session_001', 'session_006', 'session_012', 'session_013', 'session_014'] session dir:session_004\n",
      "session_num: 6\n",
      "files: ['compmonks_T2_INTERAXON-Muse2_2019-6-11_11-18-39-226599.hdf5', 'compmonks_T2_FEEDBACK_2019-6-11_11-10-48-372000.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=96853\n",
      "    Range : 0 ... 96852 =      0.000 ...   378.328 secs\n",
      "Ready.\n",
      "39493 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: Vect + LR score:0.8250295875374596\n",
      "device:muse2+ user:compmonks dir:['session_003', 'session_004', 'session_005', 'session_002', 'session_011', 'session_010', 'session_007', 'session_000', 'session_009', 'session_008', 'session_001', 'session_006', 'session_012', 'session_013', 'session_014'] session dir:session_005\n",
      "session_num: 7\n",
      "files: ['compmonks_T2_INTERAXON-Muse2_2019-6-12_7-59-55-116655.hdf5', 'compmonks_T2_FEEDBACK_2019-6-12_7-51-39-530000.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=96850\n",
      "    Range : 0 ... 96849 =      0.000 ...   378.316 secs\n",
      "Ready.\n",
      "52071 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: Vect + LR score:0.8187369436936776\n",
      "device:muse2+ user:compmonks dir:['session_003', 'session_004', 'session_005', 'session_002', 'session_011', 'session_010', 'session_007', 'session_000', 'session_009', 'session_008', 'session_001', 'session_006', 'session_012', 'session_013', 'session_014'] session dir:session_002\n",
      "session_num: 8\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-5_8-8-47-375000.hdf5', 'compmonks_T2_INTERAXON-Muse2_2019-6-5_8-16-21-81290.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=96828\n",
      "    Range : 0 ... 96827 =      0.000 ...   378.230 secs\n",
      "Ready.\n",
      "66447 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: Vect + LR score:0.8175788986104788\n",
      "device:muse2+ user:compmonks dir:['session_003', 'session_004', 'session_005', 'session_002', 'session_011', 'session_010', 'session_007', 'session_000', 'session_009', 'session_008', 'session_001', 'session_006', 'session_012', 'session_013', 'session_014'] session dir:session_011\n",
      "session_num: 9\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-26_6-15-55-628000.hdf5', 'compmonks_T2_INTERAXON-Muse2_2019-6-26_6-23-45-437736.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=96868\n",
      "    Range : 0 ... 96867 =      0.000 ...   378.387 secs\n",
      "Ready.\n",
      "82622 events found\n",
      "Event IDs: [1 2]\n"
     ]
    }
   ],
   "source": [
    "all_results =  pd.DataFrame({'Temp' : []})\n",
    "raw = []\n",
    "session_num = 0\n",
    "the_training_path = os.path.join(the_folder_path,the_device,the_user,\"training\")\n",
    "the_additional_path = os.path.join(the_folder_path,the_device,the_user,\"additional\")\n",
    "all_sessions_data_path = list(os.walk(the_training_path)) + list(os.walk(the_additional_path))\n",
    "#\n",
    "for root, subdirs, files in all_sessions_data_path:\n",
    "    for dirs in subdirs:\n",
    "        print(\"device:{} user:{} dir:{} session dir:{}\".format(the_device,the_user,subdirs,dirs))\n",
    "        file_list = [fn for fn in os.listdir(os.path.join(root,dirs)) if fn.endswith(\"hdf5\")]\n",
    "        if len(file_list) == 2:\n",
    "            try:\n",
    "                print(\"session_num: {}\".format(session_num))\n",
    "                print(\"files: {}\".format(file_list))\n",
    "                if \"FEEDBACK\" in file_list[0]:\n",
    "                    dataF = pd.read_hdf(os.path.join(root,dirs,file_list[0]),'data')\n",
    "                    dataA = pd.read_hdf(os.path.join(root,dirs,file_list[1]),'EEG')\n",
    "                else:\n",
    "                    dataF = pd.read_hdf(os.path.join(root,dirs,file_list[1]),'data')\n",
    "                    dataA = pd.read_hdf(os.path.join(root,dirs,file_list[0]),'EEG')\n",
    "                #\n",
    "                dataA['Stim'] = np.nan\n",
    "                prev_marker = 0\n",
    "                for index,row in dataA.iterrows():\n",
    "                    new_marker = dataF.iloc[dataF.index.get_loc(pd.to_datetime(index),method='nearest')]['marker'].astype(int)\n",
    "                    if prev_marker == 0:\n",
    "                        if new_marker != 0:\n",
    "                            row['Stim'] = new_marker\n",
    "                            prev_marker = new_marker\n",
    "                        else:\n",
    "                            row['Stim'] = 0\n",
    "                    else:\n",
    "                        row['Stim'] = 0\n",
    "                        prev_marker = new_marker\n",
    "\n",
    "                channel_names = list(dataA.keys())\n",
    "                # temporary fix on possibly erroneous channel labelling on some of the former data\n",
    "                for _it,_ch in enumerate(channel_names):\n",
    "                    if _ch == \"P2\":\n",
    "                        channel_names[_it] = \"O2\"\n",
    "                #\n",
    "                channel_types = ['eeg'] * (len(list(dataA.keys()))-1) + ['stim']\n",
    "                the_data = dataA.values[:].T\n",
    "                the_data[:-1] *= 1e-6 if the_units == \"uVolts\" else 1\n",
    "                info = create_info(ch_names = channel_names, \n",
    "                                   ch_types = channel_types,\n",
    "                                   sfreq = the_freq, \n",
    "                                   montage = the_montage)\n",
    "                raw.append(RawArray(data = the_data, info = info))\n",
    "                the_raw = concatenate_raws(raw)\n",
    "                the_events = find_events(the_raw)\n",
    "                the_epochs = Epochs(the_raw,\n",
    "                                    events = the_events, \n",
    "                                    event_id = the_markers,\n",
    "                                    tmin = -0.1, tmax = 0.7,\n",
    "                                    baseline = None,\n",
    "                                    reject = {'eeg': 75e-6},\n",
    "                                    preload = True,\n",
    "                                    verbose = False,\n",
    "                                    picks = list(range(len(channel_names)-1))\n",
    "                                   )\n",
    "                #\n",
    "                the_epochs.pick_types(eeg=True)\n",
    "                X = the_epochs.get_data() * 1e6\n",
    "                y = the_epochs.events[:, -1]\n",
    "                cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "                auc = []\n",
    "                methods = []\n",
    "                #params = []\n",
    "                # cross validation AUC score by classifier\n",
    "                for m in clfs:\n",
    "                    #clf = GridSearchCV(clfs[m], grid_params)\n",
    "                    #clf.fit(train, y_train)\n",
    "                    res = cross_val_score(clfs[m], X, y==2, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "                    auc.extend(res)\n",
    "                    methods.extend([m]*len(res))\n",
    "                the_best_score = max(auc)\n",
    "                the_best_method = methods[auc.index(the_best_score)]\n",
    "                print(\"The best predictor is: {} score:{}\".format(the_best_method, the_best_score))\n",
    "                # plot\n",
    "                results = pd.DataFrame(data=auc, columns=['AUC'])\n",
    "                results['Method'] = methods\n",
    "                results['session_num'] = session_num\n",
    "                if all_results.empty:\n",
    "                    palette = sns.color_palette(categorical_color_palette, len(results))\n",
    "                    all_results = results.copy()\n",
    "                else:\n",
    "                    all_results = pd.concat([all_results, results], ignore_index=True, sort=False)\n",
    "                session_num +=1\n",
    "            except Exception as e:\n",
    "                print(\"ERROR: {}\".format(e))\n",
    "                pass\n",
    "# train and save best predictor with all data\n",
    "train_save(clfs[the_best_method], X, y)\n",
    "\n",
    "# plotting the accuracy comparison over sessions\n",
    "lp = sns.lineplot(x='session_num', y='AUC', hue='Method', data=all_results)\n",
    "lp.legend(loc='center right', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(the_additional_path,\"AUC.png\"),dpi = 800,format = \"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
