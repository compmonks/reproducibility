{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO\n",
    "- experiment: p300 speller\n",
    "- stimulation: rsvp 100ms(stim) / 75ms(blank) / 2500ms break between char / 15 flashes per char / random words of 10 chars\n",
    "- users tested: 1\n",
    "- devices tested : \n",
    "    - muse 2: freq 256Hz / channels TP9,AF7,AF8,TP10\n",
    "    - muse 2+: freq 256Hz / channels TP9,AF7,AF8,TP10,POz\n",
    "    - OpenBCI: freq 125Hz / channels FC3,FCz,FC4,T7,C3,Cz,C4,T8,P7,P3,Pz,P4,P8,O1,O2,Oz\n",
    "- metric used : Area Under the Curve (AUC)\n",
    "\n",
    "\n",
    "This code demonstrates the evolution of selected predictors over increasing amount of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILT-IN\n",
    "import os,sys\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "# DATAFRAMES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# SCIKIT-LEARN\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit,GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# PYRIEMANN\n",
    "from pyriemann.estimation import ERPCovariances, XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.classification import MDM\n",
    "from pyriemann.spatialfilters import Xdawn\n",
    "\n",
    "# MNE\n",
    "from mne import Epochs, find_events\n",
    "from mne.channels import read_montage\n",
    "from mne import create_info, concatenate_raws\n",
    "from mne.io import RawArray\n",
    "from mne.decoding import Vectorizer\n",
    "\n",
    "# PLOTTING\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_folder_path = \"../data/p300_speller\" # relative datasets path\n",
    "the_user = \"compmonks\" # check available users in data folder or add new ones\n",
    "the_device = \"openbci_v207\" # \"muse2+\" # \"muse2\" # \"openbci_v207\" # available devices\n",
    "the_freq = 125 # 256 (Muse) # 125 (OpenBCI) # Sampling Frequency in Hertz\n",
    "break_epoch = 2500 # ms epoch used to break between character sessions\n",
    "the_montage = \"standard_1020\" # \"standard_1005\" (Muse) # \"standard_1020\" (OpenBCI) # channels montage\n",
    "the_units = \"uVolts\" # \"uVolts\" # \"Volts\" # unit of received data from device\n",
    "the_markers = {'Non-Target': 2, 'Target': 1} # markers from stim data\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "diverging_color_palette = \"coolwarm\"\n",
    "categorical_color_palette = \"Paired\"\n",
    "\n",
    "# list of best known discriminators for P300\n",
    "clfs = OrderedDict()\n",
    "clfs['Vect + LR'] = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression())\n",
    "clfs['Vect + RegLDA'] = make_pipeline(Vectorizer(), LDA(shrinkage='auto', solver='eigen'))\n",
    "clfs['Xdawn + RegLDA'] = make_pipeline(Xdawn(2, classes=[1]), Vectorizer(), LDA(shrinkage='auto', solver='eigen'))\n",
    "clfs['ERPCov + TS'] = make_pipeline(ERPCovariances(), TangentSpace(), LogisticRegression())\n",
    "clfs['ERPCov + MDM'] = make_pipeline(ERPCovariances(), MDM())\n",
    "clfs['XdawnCov + TS + LReg'] = make_pipeline(XdawnCovariances(2),TangentSpace(metric='riemann'),LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimatorParamsDict():\n",
    "    \"\"\"# get all params of a list of estimators and return them as a distionary.\"\"\"\n",
    "    \n",
    "    pass\n",
    "#\n",
    "def train_save(self, the_predictor, the_X, the_y):\n",
    "    \"\"\" Train a given predictor formatted as a pipeline.\"\"\"\n",
    "\n",
    "    trained = the_predictor.fit(the_X,the_y)\n",
    "    joblib.dump(trained,'predictor_{}.pkl'.format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004'] session dir:session_000\n",
      "session_num: 0\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-13_16-30-4-910000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-13_16-36-59-984868.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47345\n",
      "    Range : 0 ... 47344 =      0.000 ...   378.752 secs\n",
      "Ready.\n",
      "758 events found\n",
      "Event IDs: [1 2]\n",
      "ERROR: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004'] session dir:session_001\n",
      "session_num: 0\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-14_7-37-8-594000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-14_7-44-1-824255.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47535\n",
      "    Range : 0 ... 47534 =      0.000 ...   380.272 secs\n",
      "Ready.\n",
      "1554 events found\n",
      "Event IDs: [1 2]\n",
      "ERROR: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004'] session dir:session_002\n",
      "session_num: 0\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-14_16-35-52-863000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-14_16-42-47-952357.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47340\n",
      "    Range : 0 ... 47339 =      0.000 ...   378.712 secs\n",
      "Ready.\n",
      "3088 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: ERPCov + TS score:0.8159927305770105\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004'] session dir:session_003\n",
      "session_num: 1\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-14_16-45-49-122000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-14_16-52-45-632301.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47650\n",
      "    Range : 0 ... 47649 =      0.000 ...   381.192 secs\n",
      "Ready.\n",
      "5392 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: ERPCov + TS score:0.9437519002736394\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004'] session dir:session_004\n",
      "session_num: 2\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-14_16-56-55-129000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-14_17-3-50-26202.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47585\n",
      "    Range : 0 ... 47584 =      0.000 ...   380.672 secs\n",
      "Ready.\n",
      "8430 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: ERPCov + TS score:0.9678910832756986\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004', 'session_005', 'session_006', 'session_007', 'session_008', 'session_009', 'session_010', 'session_011', 'session_012', 'session_013', 'session_014'] session dir:session_000\n",
      "session_num: 3\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-17_8-21-31-679000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-17_8-28-24-163041.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47575\n",
      "    Range : 0 ... 47574 =      0.000 ...   380.592 secs\n",
      "Ready.\n",
      "12175 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: ERPCov + TS score:0.9942104588018984\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004', 'session_005', 'session_006', 'session_007', 'session_008', 'session_009', 'session_010', 'session_011', 'session_012', 'session_013', 'session_014'] session dir:session_001\n",
      "session_num: 4\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-17_8-34-3-316000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-17_8-40-58-402225.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47405\n",
      "    Range : 0 ... 47404 =      0.000 ...   379.232 secs\n",
      "Ready.\n",
      "16685 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: ERPCov + TS score:0.9995529245648653\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004', 'session_005', 'session_006', 'session_007', 'session_008', 'session_009', 'session_010', 'session_011', 'session_012', 'session_013', 'session_014'] session dir:session_002\n",
      "session_num: 5\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-17_8-44-35-203000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-17_8-51-30-167209.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47395\n",
      "    Range : 0 ... 47394 =      0.000 ...   379.152 secs\n",
      "Ready.\n",
      "21951 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: ERPCov + TS score:1.0\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004', 'session_005', 'session_006', 'session_007', 'session_008', 'session_009', 'session_010', 'session_011', 'session_012', 'session_013', 'session_014'] session dir:session_003\n",
      "session_num: 6\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-18_9-51-16-533000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-18_9-58-9-642913.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47475\n",
      "    Range : 0 ... 47474 =      0.000 ...   379.792 secs\n",
      "Ready.\n",
      "27977 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: ERPCov + TS score:1.0\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004', 'session_005', 'session_006', 'session_007', 'session_008', 'session_009', 'session_010', 'session_011', 'session_012', 'session_013', 'session_014'] session dir:session_004\n",
      "session_num: 7\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-18_10-5-31-424000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-18_10-12-26-594676.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47500\n",
      "    Range : 0 ... 47499 =      0.000 ...   379.992 secs\n",
      "Ready.\n",
      "34760 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: ERPCov + TS score:1.0\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004', 'session_005', 'session_006', 'session_007', 'session_008', 'session_009', 'session_010', 'session_011', 'session_012', 'session_013', 'session_014'] session dir:session_005\n",
      "session_num: 8\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-18_10-19-59-320000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-18_10-26-53-26470.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47640\n",
      "    Range : 0 ... 47639 =      0.000 ...   381.112 secs\n",
      "Ready.\n",
      "42297 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: ERPCov + TS score:1.0\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004', 'session_005', 'session_006', 'session_007', 'session_008', 'session_009', 'session_010', 'session_011', 'session_012', 'session_013', 'session_014'] session dir:session_006\n",
      "session_num: 9\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-18_10-33-45-117000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-18_10-40-39-534340.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47400\n",
      "    Range : 0 ... 47399 =      0.000 ...   379.192 secs\n",
      "Ready.\n",
      "50589 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: ERPCov + TS score:1.0\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004', 'session_005', 'session_006', 'session_007', 'session_008', 'session_009', 'session_010', 'session_011', 'session_012', 'session_013', 'session_014'] session dir:session_007\n",
      "session_num: 10\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-18_10-47-33-719000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-18_10-54-28-731023.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47610\n",
      "    Range : 0 ... 47609 =      0.000 ...   380.872 secs\n",
      "Ready.\n",
      "59596 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: ERPCov + TS score:1.0\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004', 'session_005', 'session_006', 'session_007', 'session_008', 'session_009', 'session_010', 'session_011', 'session_012', 'session_013', 'session_014'] session dir:session_008\n",
      "session_num: 11\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-19_7-25-6-919000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-19_7-32-2-764106.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 47354 =      0.000 ...   378.832 secs\n",
      "Ready.\n",
      "69351 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: ERPCov + TS score:1.0\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004', 'session_005', 'session_006', 'session_007', 'session_008', 'session_009', 'session_010', 'session_011', 'session_012', 'session_013', 'session_014'] session dir:session_009\n",
      "session_num: 12\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-19_9-22-20-400000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-19_9-29-16-731631.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47390\n",
      "    Range : 0 ... 47389 =      0.000 ...   379.112 secs\n",
      "Ready.\n",
      "79824 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: ERPCov + TS score:1.0\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004', 'session_005', 'session_006', 'session_007', 'session_008', 'session_009', 'session_010', 'session_011', 'session_012', 'session_013', 'session_014'] session dir:session_010\n",
      "session_num: 13\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-26_9-26-33-917000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-26_9-33-28-105071.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47302\n",
      "    Range : 0 ... 47301 =      0.000 ...   378.408 secs\n",
      "Ready.\n",
      "92096 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: ERPCov + TS score:0.984300044851211\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004', 'session_005', 'session_006', 'session_007', 'session_008', 'session_009', 'session_010', 'session_011', 'session_012', 'session_013', 'session_014'] session dir:session_011\n",
      "session_num: 14\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-26_9-40-48-524000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-26_9-47-44-717102.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47301\n",
      "    Range : 0 ... 47300 =      0.000 ...   378.400 secs\n",
      "Ready.\n",
      "106167 events found\n",
      "Event IDs: [1 2]\n",
      "The best predictor is: ERPCov + TS score:0.9701802486769804\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004', 'session_005', 'session_006', 'session_007', 'session_008', 'session_009', 'session_010', 'session_011', 'session_012', 'session_013', 'session_014'] session dir:session_012\n",
      "session_num: 15\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-29_8-34-30-580000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-29_8-41-24-669213.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47297\n",
      "    Range : 0 ... 47296 =      0.000 ...   378.368 secs\n",
      "Ready.\n",
      "122037 events found\n",
      "Event IDs: [1 2]\n",
      "ERROR: JoblibValueError\n",
      "___________________________________________________________________________\n",
      "Multiprocessing exception:\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\appdata\\local\\programs\\python\\python35\\Lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n",
      "    188         sys.exit(msg)\n",
      "    189     main_globals = sys.modules[\"__main__\"].__dict__\n",
      "    190     if alter_argv:\n",
      "    191         sys.argv[0] = mod_spec.origin\n",
      "    192     return _run_code(code, main_globals, None,\n",
      "--> 193                      \"__main__\", mod_spec)\n",
      "        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...n354\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n",
      "    194 \n",
      "    195 def run_module(mod_name, init_globals=None,\n",
      "    196                run_name=None, alter_sys=False):\n",
      "    197     \"\"\"Execute a module's code without importing it\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\appdata\\local\\programs\\python\\python35\\Lib\\runpy.py in _run_code(code=<code object <module> at 0x000001A205FB9A50, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': r'c:\\users\\pierr\\python354\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...n354\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'c:\\\\users\\\\p...54\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...n354\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n",
      "     80                        __cached__ = cached,\n",
      "     81                        __doc__ = None,\n",
      "     82                        __loader__ = loader,\n",
      "     83                        __package__ = pkg_name,\n",
      "     84                        __spec__ = mod_spec)\n",
      "---> 85     exec(code, run_globals)\n",
      "        code = <code object <module> at 0x000001A205FB9A50, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n",
      "        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': r'c:\\users\\pierr\\python354\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...n354\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'c:\\\\users\\\\p...54\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n",
      "     86     return run_globals\n",
      "     87 \n",
      "     88 def _run_module_code(code, init_globals=None,\n",
      "     89                     mod_name=None, mod_spec=None,\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n",
      "     11     # This is added back by InteractiveShellApp.init_path()\n",
      "     12     if sys.path[0] == '':\n",
      "     13         del sys.path[0]\n",
      "     14 \n",
      "     15     from ipykernel import kernelapp as app\n",
      "---> 16     app.launch_new_instance()\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n",
      "    653 \n",
      "    654         If a global instance already exists, this reinitializes and starts it\n",
      "    655         \"\"\"\n",
      "    656         app = cls.instance(**kwargs)\n",
      "    657         app.initialize(argv)\n",
      "--> 658         app.start()\n",
      "        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n",
      "    659 \n",
      "    660 #-----------------------------------------------------------------------------\n",
      "    661 # utility functions, for convenience\n",
      "    662 #-----------------------------------------------------------------------------\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n",
      "    472             return self.subapp.start()\n",
      "    473         if self.poller is not None:\n",
      "    474             self.poller.start()\n",
      "    475         self.kernel.start()\n",
      "    476         try:\n",
      "--> 477             ioloop.IOLoop.instance().start()\n",
      "    478         except KeyboardInterrupt:\n",
      "    479             pass\n",
      "    480 \n",
      "    481 launch_new_instance = IPKernelApp.launch_instance\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n",
      "    172             )\n",
      "    173         return loop\n",
      "    174     \n",
      "    175     def start(self):\n",
      "    176         try:\n",
      "--> 177             super(ZMQIOLoop, self).start()\n",
      "        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n",
      "    178         except ZMQError as e:\n",
      "    179             if e.errno == ETERM:\n",
      "    180                 # quietly return on ETERM\n",
      "    181                 pass\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n",
      "    883                 self._events.update(event_pairs)\n",
      "    884                 while self._events:\n",
      "    885                     fd, events = self._events.popitem()\n",
      "    886                     try:\n",
      "    887                         fd_obj, handler_func = self._handlers[fd]\n",
      "--> 888                         handler_func(fd_obj, events)\n",
      "        handler_func = <function wrap.<locals>.null_wrapper>\n",
      "        fd_obj = <zmq.sugar.socket.Socket object>\n",
      "        events = 5\n",
      "    889                     except (OSError, IOError) as e:\n",
      "    890                         if errno_from_exception(e) == errno.EPIPE:\n",
      "    891                             # Happens when the client closes the connection\n",
      "    892                             pass\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n",
      "    272         # Fast path when there are no active contexts.\n",
      "    273         def null_wrapper(*args, **kwargs):\n",
      "    274             try:\n",
      "    275                 current_state = _state.contexts\n",
      "    276                 _state.contexts = cap_contexts[0]\n",
      "--> 277                 return fn(*args, **kwargs)\n",
      "        args = (<zmq.sugar.socket.Socket object>, 5)\n",
      "        kwargs = {}\n",
      "    278             finally:\n",
      "    279                 _state.contexts = current_state\n",
      "    280         null_wrapper._wrapped = True\n",
      "    281         return null_wrapper\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n",
      "    435             # dispatch events:\n",
      "    436             if events & IOLoop.ERROR:\n",
      "    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n",
      "    438                 return\n",
      "    439             if events & IOLoop.READ:\n",
      "--> 440                 self._handle_recv()\n",
      "        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n",
      "    441                 if not self.socket:\n",
      "    442                     return\n",
      "    443             if events & IOLoop.WRITE:\n",
      "    444                 self._handle_send()\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n",
      "    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n",
      "    468         else:\n",
      "    469             if self._recv_callback:\n",
      "    470                 callback = self._recv_callback\n",
      "    471                 # self._recv_callback = None\n",
      "--> 472                 self._run_callback(callback, msg)\n",
      "        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n",
      "        callback = <function wrap.<locals>.null_wrapper>\n",
      "        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n",
      "    473                 \n",
      "    474         # self.update_state()\n",
      "    475         \n",
      "    476 \n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n",
      "    409         close our socket.\"\"\"\n",
      "    410         try:\n",
      "    411             # Use a NullContext to ensure that all StackContexts are run\n",
      "    412             # inside our blanket exception handler rather than outside.\n",
      "    413             with stack_context.NullContext():\n",
      "--> 414                 callback(*args, **kwargs)\n",
      "        callback = <function wrap.<locals>.null_wrapper>\n",
      "        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n",
      "        kwargs = {}\n",
      "    415         except:\n",
      "    416             gen_log.error(\"Uncaught exception, closing connection.\",\n",
      "    417                           exc_info=True)\n",
      "    418             # Close the socket on an uncaught exception from a user callback\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n",
      "    272         # Fast path when there are no active contexts.\n",
      "    273         def null_wrapper(*args, **kwargs):\n",
      "    274             try:\n",
      "    275                 current_state = _state.contexts\n",
      "    276                 _state.contexts = cap_contexts[0]\n",
      "--> 277                 return fn(*args, **kwargs)\n",
      "        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n",
      "        kwargs = {}\n",
      "    278             finally:\n",
      "    279                 _state.contexts = current_state\n",
      "    280         null_wrapper._wrapped = True\n",
      "    281         return null_wrapper\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n",
      "    278         if self.control_stream:\n",
      "    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n",
      "    280 \n",
      "    281         def make_dispatcher(stream):\n",
      "    282             def dispatcher(msg):\n",
      "--> 283                 return self.dispatch_shell(stream, msg)\n",
      "        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n",
      "    284             return dispatcher\n",
      "    285 \n",
      "    286         for s in self.shell_streams:\n",
      "    287             s.on_recv(make_dispatcher(s), copy=False)\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 7, 1, 21, 10, 49, 792582, tzinfo=tzutc()), 'msg_id': '816EA7A61B374AC2916F5774B8984EE2', 'msg_type': 'execute_request', 'session': '70FF3121849846E988CB71C1C0498881', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '816EA7A61B374AC2916F5774B8984EE2', 'msg_type': 'execute_request', 'parent_header': {}})\n",
      "    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n",
      "    231         else:\n",
      "    232             self.log.debug(\"%s: %s\", msg_type, msg)\n",
      "    233             self.pre_handler_hook()\n",
      "    234             try:\n",
      "--> 235                 handler(stream, idents, msg)\n",
      "        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n",
      "        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n",
      "        idents = [b'70FF3121849846E988CB71C1C0498881']\n",
      "        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 7, 1, 21, 10, 49, 792582, tzinfo=tzutc()), 'msg_id': '816EA7A61B374AC2916F5774B8984EE2', 'msg_type': 'execute_request', 'session': '70FF3121849846E988CB71C1C0498881', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '816EA7A61B374AC2916F5774B8984EE2', 'msg_type': 'execute_request', 'parent_header': {}}\n",
      "    236             except Exception:\n",
      "    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n",
      "    238             finally:\n",
      "    239                 self.post_handler_hook()\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'70FF3121849846E988CB71C1C0498881'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 7, 1, 21, 10, 49, 792582, tzinfo=tzutc()), 'msg_id': '816EA7A61B374AC2916F5774B8984EE2', 'msg_type': 'execute_request', 'session': '70FF3121849846E988CB71C1C0498881', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '816EA7A61B374AC2916F5774B8984EE2', 'msg_type': 'execute_request', 'parent_header': {}})\n",
      "    394         if not silent:\n",
      "    395             self.execution_count += 1\n",
      "    396             self._publish_execute_input(code, parent, self.execution_count)\n",
      "    397 \n",
      "    398         reply_content = self.do_execute(code, silent, store_history,\n",
      "--> 399                                         user_expressions, allow_stdin)\n",
      "        user_expressions = {}\n",
      "        allow_stdin = True\n",
      "    400 \n",
      "    401         # Flush output before sending the reply.\n",
      "    402         sys.stdout.flush()\n",
      "    403         sys.stderr.flush()\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n",
      "    191 \n",
      "    192         self._forward_input(allow_stdin)\n",
      "    193 \n",
      "    194         reply_content = {}\n",
      "    195         try:\n",
      "--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "        res = undefined\n",
      "        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n",
      "        code = 'all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")'\n",
      "        store_history = True\n",
      "        silent = False\n",
      "    197         finally:\n",
      "    198             self._restore_input()\n",
      "    199 \n",
      "    200         if res.error_before_exec is not None:\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")',), **kwargs={'silent': False, 'store_history': True})\n",
      "    528             )\n",
      "    529         self.payload_manager.write_payload(payload)\n",
      "    530 \n",
      "    531     def run_cell(self, *args, **kwargs):\n",
      "    532         self._last_traceback = None\n",
      "--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n",
      "        args = ('all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")',)\n",
      "        kwargs = {'silent': False, 'store_history': True}\n",
      "    534 \n",
      "    535     def _showtraceback(self, etype, evalue, stb):\n",
      "    536         # try to preserve ordering of tracebacks and print statements\n",
      "    537         sys.stdout.flush()\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")', store_history=True, silent=False, shell_futures=True)\n",
      "   2723                 self.displayhook.exec_result = result\n",
      "   2724 \n",
      "   2725                 # Execute the user code\n",
      "   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n",
      "   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n",
      "-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n",
      "        interactivity = 'last_expr'\n",
      "        compiler = <IPython.core.compilerop.CachingCompiler object>\n",
      "   2729                 \n",
      "   2730                 self.last_execution_succeeded = not has_raised\n",
      "   2731                 self.last_execution_result = result\n",
      "   2732 \n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.For object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-4-a25bd94358df>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1a21db125f8, executio..._before_exec=None error_in_exec=None result=None>)\n",
      "   2845 \n",
      "   2846         try:\n",
      "   2847             for i, node in enumerate(to_run_exec):\n",
      "   2848                 mod = ast.Module([node])\n",
      "   2849                 code = compiler(mod, cell_name, \"exec\")\n",
      "-> 2850                 if self.run_code(code, result):\n",
      "        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n",
      "        code = <code object <module> at 0x000001A21DB0DD20, file \"<ipython-input-4-a25bd94358df>\", line 8>\n",
      "        result = <ExecutionResult object at 1a21db125f8, executio..._before_exec=None error_in_exec=None result=None>\n",
      "   2851                     return True\n",
      "   2852 \n",
      "   2853             for i, node in enumerate(to_run_interactive):\n",
      "   2854                 mod = ast.Interactive([node])\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001A21DB0DD20, file \"<ipython-input-4-a25bd94358df>\", line 8>, result=<ExecutionResult object at 1a21db125f8, executio..._before_exec=None error_in_exec=None result=None>)\n",
      "   2905         outflag = True  # happens in more places, so it's easier as default\n",
      "   2906         try:\n",
      "   2907             try:\n",
      "   2908                 self.hooks.pre_run_code_hook()\n",
      "   2909                 #rprint('Running code', repr(code_obj)) # dbg\n",
      "-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "        code_obj = <code object <module> at 0x000001A21DB0DD20, file \"<ipython-input-4-a25bd94358df>\", line 8>\n",
      "        self.user_global_ns = {'ERPCovariances': <class 'pyriemann.estimation.ERPCovariances'>, 'Epochs': <class 'mne.epochs.Epochs'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"# BUILT-IN\\nimport os,sys\\nimport math\\nfrom collec..._ipython().run_line_magic('matplotlib', 'inline')\", 'the_folder_path = \"../data/p300_speller\" # relat...gentSpace(metric=\\'riemann\\'),LogisticRegression())', 'def estimatorParamsDict():\\n    \"\"\"# get all para...redictor_{}.pkl\\'.format(datetime.datetime.now()))', 'all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")'], 'LDA': <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MDM': <class 'pyriemann.classification.MDM'>, 'OrderedDict': <class 'collections.OrderedDict'>, 'Out': {}, 'RawArray': <class 'mne.io.array.array.RawArray'>, ...}\n",
      "        self.user_ns = {'ERPCovariances': <class 'pyriemann.estimation.ERPCovariances'>, 'Epochs': <class 'mne.epochs.Epochs'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"# BUILT-IN\\nimport os,sys\\nimport math\\nfrom collec..._ipython().run_line_magic('matplotlib', 'inline')\", 'the_folder_path = \"../data/p300_speller\" # relat...gentSpace(metric=\\'riemann\\'),LogisticRegression())', 'def estimatorParamsDict():\\n    \"\"\"# get all para...redictor_{}.pkl\\'.format(datetime.datetime.now()))', 'all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")'], 'LDA': <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MDM': <class 'pyriemann.classification.MDM'>, 'OrderedDict': <class 'collections.OrderedDict'>, 'Out': {}, 'RawArray': <class 'mne.io.array.array.RawArray'>, ...}\n",
      "   2911             finally:\n",
      "   2912                 # Reset our crash handler in place\n",
      "   2913                 sys.excepthook = old_excepthook\n",
      "   2914         except SystemExit as e:\n",
      "\n",
      "...........................................................................\n",
      "D:\\Dropbox (Personal)\\XXXX_PERS_Git\\reproducibility\\code\\<ipython-input-4-a25bd94358df> in <module>()\n",
      "     70                 #params = []\n",
      "     71                 # cross validation AUC score by classifier\n",
      "     72                 for m in clfs:\n",
      "     73                     #clf = GridSearchCV(clfs[m], grid_params)\n",
      "     74                     #clf.fit(train, y_train)\n",
      "---> 75                     res = cross_val_score(clfs[m], X, y==2, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
      "     76                     auc.extend(res)\n",
      "     77                     methods.extend([m]*len(res))\n",
      "     78                 the_best_score = max(auc)\n",
      "     79                 the_best_method = methods[auc.index(the_best_score)]\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_val_score(estimator=Pipeline(memory=None,\n",
      "     steps=[('erpcovarianc...0.0001,\n",
      "          verbose=0, warm_start=False))]), X=array([[[ -5622.37988281,  -5626.40332031,  -562...53.89135742,  -2733.17114258,  -2733.17114258]]]), y=array([ True, False,  True, ...,  True,  True,  True]), groups=None, scoring='roc_auc', cv=StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=0.25,\n",
      "            train_size=None), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n",
      "    337     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n",
      "    338                                 scoring={'score': scorer}, cv=cv,\n",
      "    339                                 return_train_score=False,\n",
      "    340                                 n_jobs=n_jobs, verbose=verbose,\n",
      "    341                                 fit_params=fit_params,\n",
      "--> 342                                 pre_dispatch=pre_dispatch)\n",
      "        pre_dispatch = '2*n_jobs'\n",
      "    343     return cv_results['test_score']\n",
      "    344 \n",
      "    345 \n",
      "    346 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_validate(estimator=Pipeline(memory=None,\n",
      "     steps=[('erpcovarianc...0.0001,\n",
      "          verbose=0, warm_start=False))]), X=array([[[ -5622.37988281,  -5626.40332031,  -562...53.89135742,  -2733.17114258,  -2733.17114258]]]), y=array([ True, False,  True, ...,  True,  True,  True]), groups=None, scoring={'score': make_scorer(roc_auc_score, needs_threshold=True)}, cv=StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=0.25,\n",
      "            train_size=None), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)\n",
      "    201     scores = parallel(\n",
      "    202         delayed(_fit_and_score)(\n",
      "    203             clone(estimator), X, y, scorers, train, test, verbose, None,\n",
      "    204             fit_params, return_train_score=return_train_score,\n",
      "    205             return_times=True)\n",
      "--> 206         for train, test in cv.split(X, y, groups))\n",
      "        cv.split = <bound method StratifiedShuffleSplit.split of St...42, test_size=0.25,\n",
      "            train_size=None)>\n",
      "        X = array([[[ -5622.37988281,  -5626.40332031,  -562...53.89135742,  -2733.17114258,  -2733.17114258]]])\n",
      "        y = array([ True, False,  True, ...,  True,  True,  True])\n",
      "        groups = None\n",
      "    207 \n",
      "    208     if return_train_score:\n",
      "    209         train_scores, test_scores, fit_times, score_times = zip(*scores)\n",
      "    210         train_scores = _aggregate_score_dicts(train_scores)\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n",
      "    784             if pre_dispatch == \"all\" or n_jobs == 1:\n",
      "    785                 # The iterable was consumed all at once by the above for loop.\n",
      "    786                 # No need to wait for async callbacks to trigger to\n",
      "    787                 # consumption.\n",
      "    788                 self._iterating = False\n",
      "--> 789             self.retrieve()\n",
      "        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n",
      "    790             # Make sure that we get a last message telling us we are done\n",
      "    791             elapsed_time = time.time() - self._start_time\n",
      "    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n",
      "    793                         (len(self._output), len(self._output),\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Sub-process traceback:\n",
      "---------------------------------------------------------------------------\n",
      "ValueError                                         Tue Jul  2 04:41:38 2019\n",
      "PID: 1896         Python 3.5.4: c:\\users\\pierr\\python354\\scripts\\python.exe\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n",
      "     steps=[('erpcovarianc...0.0001,\n",
      "          verbose=0, warm_start=False))]), memmap([[[ -5622.37988281,  -5626.40332031,  -56...53.89135742,  -2733.17114258,  -2733.17114258]]]), array([ True, False,  True, ...,  True,  True,  True]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([31322, 24764, 28647, ..., 33508, 12434,   625], dtype=int64), array([36186,  5550, 36712, ..., 33612, 25257, 23974], dtype=int64), 0, None, None), {'return_times': True, 'return_train_score': False})]\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        func = <function _fit_and_score>\n",
      "        args = (Pipeline(memory=None,\n",
      "     steps=[('erpcovarianc...0.0001,\n",
      "          verbose=0, warm_start=False))]), memmap([[[ -5622.37988281,  -5626.40332031,  -56...53.89135742,  -2733.17114258,  -2733.17114258]]]), array([ True, False,  True, ...,  True,  True,  True]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([31322, 24764, 28647, ..., 33508, 12434,   625], dtype=int64), array([36186,  5550, 36712, ..., 33612, 25257, 23974], dtype=int64), 0, None, None)\n",
      "        kwargs = {'return_times': True, 'return_train_score': False}\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n",
      "     steps=[('erpcovarianc...0.0001,\n",
      "          verbose=0, warm_start=False))]), X=memmap([[[ -5622.37988281,  -5626.40332031,  -56...53.89135742,  -2733.17114258,  -2733.17114258]]]), y=array([ True, False,  True, ...,  True,  True,  True]), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([31322, 24764, 28647, ..., 33508, 12434,   625], dtype=int64), test=array([36186,  5550, 36712, ..., 33612, 25257, 23974], dtype=int64), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n",
      "    453 \n",
      "    454     try:\n",
      "    455         if y_train is None:\n",
      "    456             estimator.fit(X_train, **fit_params)\n",
      "    457         else:\n",
      "--> 458             estimator.fit(X_train, y_train, **fit_params)\n",
      "        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n",
      "          verbose=0, warm_start=False))])>\n",
      "        X_train = memmap([[[ -74838.171875  ,  -74838.171875  ,  -....20117188,  -12211.74121094,  -12224.23535156]]])\n",
      "        y_train = array([ True,  True,  True, ..., False, False,  True])\n",
      "        fit_params = {}\n",
      "    459 \n",
      "    460     except Exception as e:\n",
      "    461         # Note fit time as time until error\n",
      "    462         fit_time = time.time() - start_time\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n",
      "     steps=[('erpcovarianc...0.0001,\n",
      "          verbose=0, warm_start=False))]), X=memmap([[[ -74838.171875  ,  -74838.171875  ,  -....20117188,  -12211.74121094,  -12224.23535156]]]), y=array([ True,  True,  True, ..., False, False,  True]), **fit_params={})\n",
      "    243         Returns\n",
      "    244         -------\n",
      "    245         self : Pipeline\n",
      "    246             This estimator\n",
      "    247         \"\"\"\n",
      "--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n",
      "        Xt = undefined\n",
      "        fit_params = {}\n",
      "        self._fit = <bound method Pipeline._fit of Pipeline(memory=N....0001,\n",
      "          verbose=0, warm_start=False))])>\n",
      "        X = memmap([[[ -74838.171875  ,  -74838.171875  ,  -....20117188,  -12211.74121094,  -12224.23535156]]])\n",
      "        y = array([ True,  True,  True, ..., False, False,  True])\n",
      "    249         if self._final_estimator is not None:\n",
      "    250             self._final_estimator.fit(Xt, y, **fit_params)\n",
      "    251         return self\n",
      "    252 \n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n",
      "     steps=[('erpcovarianc...0.0001,\n",
      "          verbose=0, warm_start=False))]), X=memmap([[[ -74838.171875  ,  -74838.171875  ,  -....20117188,  -12211.74121094,  -12224.23535156]]]), y=array([ True,  True,  True, ..., False, False,  True]), **fit_params={})\n",
      "    208                 else:\n",
      "    209                     cloned_transformer = clone(transformer)\n",
      "    210                 # Fit or load from cache the current transfomer\n",
      "    211                 Xt, fitted_transformer = fit_transform_one_cached(\n",
      "    212                     cloned_transformer, None, Xt, y,\n",
      "--> 213                     **fit_params_steps[name])\n",
      "        fit_params_steps = {'erpcovariances': {}, 'logisticregression': {}, 'tangentspace': {}}\n",
      "        name = 'tangentspace'\n",
      "    214                 # Replace the transformer of the step with the fitted\n",
      "    215                 # transformer. This is necessary when loading the transformer\n",
      "    216                 # from the cache.\n",
      "    217                 self.steps[step_idx] = (name, fitted_transformer)\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x000002BEBBCDF598>), *args=(TangentSpace(metric='riemann', tsupdate=False), None, array([[[  2.87909383,   3.65090398,   3.6462735...09549564,\n",
      "          40.1357139 ,  67.75734566]]]), array([ True,  True,  True, ..., False, False,  True])), **kwargs={})\n",
      "    357     # Should be a light as possible (for speed)\n",
      "    358     def __init__(self, func):\n",
      "    359         self.func = func\n",
      "    360 \n",
      "    361     def __call__(self, *args, **kwargs):\n",
      "--> 362         return self.func(*args, **kwargs)\n",
      "        self.func = <function _fit_transform_one>\n",
      "        args = (TangentSpace(metric='riemann', tsupdate=False), None, array([[[  2.87909383,   3.65090398,   3.6462735...09549564,\n",
      "          40.1357139 ,  67.75734566]]]), array([ True,  True,  True, ..., False, False,  True]))\n",
      "        kwargs = {}\n",
      "    363 \n",
      "    364     def call_and_shelve(self, *args, **kwargs):\n",
      "    365         return NotMemorizedResult(self.func(*args, **kwargs))\n",
      "    366 \n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=TangentSpace(metric='riemann', tsupdate=False), weight=None, X=array([[[  2.87909383,   3.65090398,   3.6462735...09549564,\n",
      "          40.1357139 ,  67.75734566]]]), y=array([ True,  True,  True, ..., False, False,  True]), **fit_params={})\n",
      "    576 \n",
      "    577 \n",
      "    578 def _fit_transform_one(transformer, weight, X, y,\n",
      "    579                        **fit_params):\n",
      "    580     if hasattr(transformer, 'fit_transform'):\n",
      "--> 581         res = transformer.fit_transform(X, y, **fit_params)\n",
      "        res = undefined\n",
      "        transformer.fit_transform = <bound method TangentSpace.fit_transform of TangentSpace(metric='riemann', tsupdate=False)>\n",
      "        X = array([[[  2.87909383,   3.65090398,   3.6462735...09549564,\n",
      "          40.1357139 ,  67.75734566]]])\n",
      "        y = array([ True,  True,  True, ..., False, False,  True])\n",
      "        fit_params = {}\n",
      "    582     else:\n",
      "    583         res = transformer.fit(X, y, **fit_params).transform(X)\n",
      "    584     # if we have a weight for this transformer, multiply output\n",
      "    585     if weight is None:\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\pyriemann\\tangentspace.py in fit_transform(self=TangentSpace(metric='riemann', tsupdate=False), X=array([[[  2.87909383,   3.65090398,   3.6462735...09549564,\n",
      "          40.1357139 ,  67.75734566]]]), y=array([ True,  True,  True, ..., False, False,  True]), sample_weight=None)\n",
      "    163             the tangent space projection of the matrices.\n",
      "    164         \"\"\"\n",
      "    165         # compute mean covariance\n",
      "    166         self._check_reference_points(X)\n",
      "    167         self.reference_ = mean_covariance(X, metric=self.metric,\n",
      "--> 168                                           sample_weight=sample_weight)\n",
      "        sample_weight = None\n",
      "    169         return tangent_space(X, self.reference_)\n",
      "    170 \n",
      "    171     def inverse_transform(self, X, y=None):\n",
      "    172         \"\"\"Inverse transform.\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\pyriemann\\utils\\mean.py in mean_covariance(covmats=array([[[  2.87909383,   3.65090398,   3.6462735...09549564,\n",
      "          40.1357139 ,  67.75734566]]]), metric='riemann', sample_weight=None, *args=())\n",
      "    327 \n",
      "    328     \"\"\"\n",
      "    329     if callable(metric):\n",
      "    330         C = metric(covmats, sample_weight=sample_weight, *args)\n",
      "    331     else:\n",
      "--> 332         C = mean_methods[metric](covmats, sample_weight=sample_weight, *args)\n",
      "        C = undefined\n",
      "        metric = 'riemann'\n",
      "        covmats = array([[[  2.87909383,   3.65090398,   3.6462735...09549564,\n",
      "          40.1357139 ,  67.75734566]]])\n",
      "        sample_weight = None\n",
      "        args = ()\n",
      "    333     return C\n",
      "    334 \n",
      "    335 mean_methods = {'riemann': mean_riemann,\n",
      "    336                 'logeuclid': mean_logeuclid,\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\pyriemann\\utils\\mean.py in mean_riemann(covmats=array([[[  2.87909383,   3.65090398,   3.6462735...09549564,\n",
      "          40.1357139 ,  67.75734566]]]), tol=1e-08, maxiter=50, init=None, sample_weight=array([3.22248002e-05, 3.22248002e-05, 3.2224800... 3.22248002e-05, 3.22248002e-05, 3.22248002e-05]))\n",
      "     60             tmp = numpy.dot(numpy.dot(Cm12, covmats[index, :, :]), Cm12)\n",
      "     61             J += sample_weight[index] * logm(tmp)\n",
      "     62 \n",
      "     63         crit = numpy.linalg.norm(J, ord='fro')\n",
      "     64         h = nu * crit\n",
      "---> 65         C = numpy.dot(numpy.dot(C12, expm(nu * J)), C12)\n",
      "        C = array([[ 2.87909383,  3.65090398,  3.64627356, .... 47.77027039,\n",
      "        44.84714588, 90.28788688]])\n",
      "        C12 = array([[0.44748196, 0.28667318, 0.35827109, ...,....., 1.35533648, 1.48319638,\n",
      "        7.40033399]])\n",
      "        nu = 1.0\n",
      "        J = array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "    ...an],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]])\n",
      "     66         if h < tau:\n",
      "     67             nu = 0.95 * nu\n",
      "     68             tau = h\n",
      "     69         else:\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\pyriemann\\utils\\base.py in expm(Ci=array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "    ...an],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]]))\n",
      "     57 \n",
      "     58     :param Ci: the coavriance matrix\n",
      "     59     :returns: the matrix exponential\n",
      "     60 \n",
      "     61     \"\"\"\n",
      "---> 62     return _matrix_operator(Ci, numpy.exp)\n",
      "        Ci = array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "    ...an],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]])\n",
      "     63 \n",
      "     64 \n",
      "     65 def invsqrtm(Ci):\n",
      "     66     \"\"\"Return the inverse matrix square root of a covariance matrix defined by :\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\pyriemann\\utils\\base.py in _matrix_operator(Ci=array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "    ...an],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]]), operator=<ufunc 'exp'>)\n",
      "      5 \n",
      "      6 \n",
      "      7 def _matrix_operator(Ci, operator):\n",
      "      8     \"\"\"matrix equivalent of an operator.\"\"\"\n",
      "      9     if Ci.dtype.char in typecodes['AllFloat'] and not numpy.isfinite(Ci).all():\n",
      "---> 10         raise ValueError(\"Covariance matrices must be positive definite. Add regularization to avoid this error.\")\n",
      "     11     eigvals, eigvects = scipy.linalg.eigh(Ci, check_finite=False)\n",
      "     12     eigvals = numpy.diag(operator(eigvals))\n",
      "     13     Out = numpy.dot(numpy.dot(eigvects, eigvals), eigvects.T)\n",
      "     14     return Out\n",
      "\n",
      "ValueError: Covariance matrices must be positive definite. Add regularization to avoid this error.\n",
      "___________________________________________________________________________\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004', 'session_005', 'session_006', 'session_007', 'session_008', 'session_009', 'session_010', 'session_011', 'session_012', 'session_013', 'session_014'] session dir:session_013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session_num: 15\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-29_9-2-0-692000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-29_9-8-55-140476.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47308\n",
      "    Range : 0 ... 47307 =      0.000 ...   378.456 secs\n",
      "Ready.\n",
      "139706 events found\n",
      "Event IDs: [1 2]\n",
      "ERROR: JoblibValueError\n",
      "___________________________________________________________________________\n",
      "Multiprocessing exception:\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\appdata\\local\\programs\\python\\python35\\Lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n",
      "    188         sys.exit(msg)\n",
      "    189     main_globals = sys.modules[\"__main__\"].__dict__\n",
      "    190     if alter_argv:\n",
      "    191         sys.argv[0] = mod_spec.origin\n",
      "    192     return _run_code(code, main_globals, None,\n",
      "--> 193                      \"__main__\", mod_spec)\n",
      "        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...n354\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n",
      "    194 \n",
      "    195 def run_module(mod_name, init_globals=None,\n",
      "    196                run_name=None, alter_sys=False):\n",
      "    197     \"\"\"Execute a module's code without importing it\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\appdata\\local\\programs\\python\\python35\\Lib\\runpy.py in _run_code(code=<code object <module> at 0x000001A205FB9A50, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': r'c:\\users\\pierr\\python354\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...n354\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'c:\\\\users\\\\p...54\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...n354\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n",
      "     80                        __cached__ = cached,\n",
      "     81                        __doc__ = None,\n",
      "     82                        __loader__ = loader,\n",
      "     83                        __package__ = pkg_name,\n",
      "     84                        __spec__ = mod_spec)\n",
      "---> 85     exec(code, run_globals)\n",
      "        code = <code object <module> at 0x000001A205FB9A50, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n",
      "        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': r'c:\\users\\pierr\\python354\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...n354\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'c:\\\\users\\\\p...54\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n",
      "     86     return run_globals\n",
      "     87 \n",
      "     88 def _run_module_code(code, init_globals=None,\n",
      "     89                     mod_name=None, mod_spec=None,\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n",
      "     11     # This is added back by InteractiveShellApp.init_path()\n",
      "     12     if sys.path[0] == '':\n",
      "     13         del sys.path[0]\n",
      "     14 \n",
      "     15     from ipykernel import kernelapp as app\n",
      "---> 16     app.launch_new_instance()\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n",
      "    653 \n",
      "    654         If a global instance already exists, this reinitializes and starts it\n",
      "    655         \"\"\"\n",
      "    656         app = cls.instance(**kwargs)\n",
      "    657         app.initialize(argv)\n",
      "--> 658         app.start()\n",
      "        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n",
      "    659 \n",
      "    660 #-----------------------------------------------------------------------------\n",
      "    661 # utility functions, for convenience\n",
      "    662 #-----------------------------------------------------------------------------\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n",
      "    472             return self.subapp.start()\n",
      "    473         if self.poller is not None:\n",
      "    474             self.poller.start()\n",
      "    475         self.kernel.start()\n",
      "    476         try:\n",
      "--> 477             ioloop.IOLoop.instance().start()\n",
      "    478         except KeyboardInterrupt:\n",
      "    479             pass\n",
      "    480 \n",
      "    481 launch_new_instance = IPKernelApp.launch_instance\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n",
      "    172             )\n",
      "    173         return loop\n",
      "    174     \n",
      "    175     def start(self):\n",
      "    176         try:\n",
      "--> 177             super(ZMQIOLoop, self).start()\n",
      "        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n",
      "    178         except ZMQError as e:\n",
      "    179             if e.errno == ETERM:\n",
      "    180                 # quietly return on ETERM\n",
      "    181                 pass\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n",
      "    883                 self._events.update(event_pairs)\n",
      "    884                 while self._events:\n",
      "    885                     fd, events = self._events.popitem()\n",
      "    886                     try:\n",
      "    887                         fd_obj, handler_func = self._handlers[fd]\n",
      "--> 888                         handler_func(fd_obj, events)\n",
      "        handler_func = <function wrap.<locals>.null_wrapper>\n",
      "        fd_obj = <zmq.sugar.socket.Socket object>\n",
      "        events = 5\n",
      "    889                     except (OSError, IOError) as e:\n",
      "    890                         if errno_from_exception(e) == errno.EPIPE:\n",
      "    891                             # Happens when the client closes the connection\n",
      "    892                             pass\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n",
      "    272         # Fast path when there are no active contexts.\n",
      "    273         def null_wrapper(*args, **kwargs):\n",
      "    274             try:\n",
      "    275                 current_state = _state.contexts\n",
      "    276                 _state.contexts = cap_contexts[0]\n",
      "--> 277                 return fn(*args, **kwargs)\n",
      "        args = (<zmq.sugar.socket.Socket object>, 5)\n",
      "        kwargs = {}\n",
      "    278             finally:\n",
      "    279                 _state.contexts = current_state\n",
      "    280         null_wrapper._wrapped = True\n",
      "    281         return null_wrapper\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n",
      "    435             # dispatch events:\n",
      "    436             if events & IOLoop.ERROR:\n",
      "    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n",
      "    438                 return\n",
      "    439             if events & IOLoop.READ:\n",
      "--> 440                 self._handle_recv()\n",
      "        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n",
      "    441                 if not self.socket:\n",
      "    442                     return\n",
      "    443             if events & IOLoop.WRITE:\n",
      "    444                 self._handle_send()\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n",
      "    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n",
      "    468         else:\n",
      "    469             if self._recv_callback:\n",
      "    470                 callback = self._recv_callback\n",
      "    471                 # self._recv_callback = None\n",
      "--> 472                 self._run_callback(callback, msg)\n",
      "        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n",
      "        callback = <function wrap.<locals>.null_wrapper>\n",
      "        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n",
      "    473                 \n",
      "    474         # self.update_state()\n",
      "    475         \n",
      "    476 \n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n",
      "    409         close our socket.\"\"\"\n",
      "    410         try:\n",
      "    411             # Use a NullContext to ensure that all StackContexts are run\n",
      "    412             # inside our blanket exception handler rather than outside.\n",
      "    413             with stack_context.NullContext():\n",
      "--> 414                 callback(*args, **kwargs)\n",
      "        callback = <function wrap.<locals>.null_wrapper>\n",
      "        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n",
      "        kwargs = {}\n",
      "    415         except:\n",
      "    416             gen_log.error(\"Uncaught exception, closing connection.\",\n",
      "    417                           exc_info=True)\n",
      "    418             # Close the socket on an uncaught exception from a user callback\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n",
      "    272         # Fast path when there are no active contexts.\n",
      "    273         def null_wrapper(*args, **kwargs):\n",
      "    274             try:\n",
      "    275                 current_state = _state.contexts\n",
      "    276                 _state.contexts = cap_contexts[0]\n",
      "--> 277                 return fn(*args, **kwargs)\n",
      "        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n",
      "        kwargs = {}\n",
      "    278             finally:\n",
      "    279                 _state.contexts = current_state\n",
      "    280         null_wrapper._wrapped = True\n",
      "    281         return null_wrapper\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n",
      "    278         if self.control_stream:\n",
      "    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n",
      "    280 \n",
      "    281         def make_dispatcher(stream):\n",
      "    282             def dispatcher(msg):\n",
      "--> 283                 return self.dispatch_shell(stream, msg)\n",
      "        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n",
      "    284             return dispatcher\n",
      "    285 \n",
      "    286         for s in self.shell_streams:\n",
      "    287             s.on_recv(make_dispatcher(s), copy=False)\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 7, 1, 21, 10, 49, 792582, tzinfo=tzutc()), 'msg_id': '816EA7A61B374AC2916F5774B8984EE2', 'msg_type': 'execute_request', 'session': '70FF3121849846E988CB71C1C0498881', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '816EA7A61B374AC2916F5774B8984EE2', 'msg_type': 'execute_request', 'parent_header': {}})\n",
      "    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n",
      "    231         else:\n",
      "    232             self.log.debug(\"%s: %s\", msg_type, msg)\n",
      "    233             self.pre_handler_hook()\n",
      "    234             try:\n",
      "--> 235                 handler(stream, idents, msg)\n",
      "        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n",
      "        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n",
      "        idents = [b'70FF3121849846E988CB71C1C0498881']\n",
      "        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 7, 1, 21, 10, 49, 792582, tzinfo=tzutc()), 'msg_id': '816EA7A61B374AC2916F5774B8984EE2', 'msg_type': 'execute_request', 'session': '70FF3121849846E988CB71C1C0498881', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '816EA7A61B374AC2916F5774B8984EE2', 'msg_type': 'execute_request', 'parent_header': {}}\n",
      "    236             except Exception:\n",
      "    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n",
      "    238             finally:\n",
      "    239                 self.post_handler_hook()\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'70FF3121849846E988CB71C1C0498881'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 7, 1, 21, 10, 49, 792582, tzinfo=tzutc()), 'msg_id': '816EA7A61B374AC2916F5774B8984EE2', 'msg_type': 'execute_request', 'session': '70FF3121849846E988CB71C1C0498881', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '816EA7A61B374AC2916F5774B8984EE2', 'msg_type': 'execute_request', 'parent_header': {}})\n",
      "    394         if not silent:\n",
      "    395             self.execution_count += 1\n",
      "    396             self._publish_execute_input(code, parent, self.execution_count)\n",
      "    397 \n",
      "    398         reply_content = self.do_execute(code, silent, store_history,\n",
      "--> 399                                         user_expressions, allow_stdin)\n",
      "        user_expressions = {}\n",
      "        allow_stdin = True\n",
      "    400 \n",
      "    401         # Flush output before sending the reply.\n",
      "    402         sys.stdout.flush()\n",
      "    403         sys.stderr.flush()\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n",
      "    191 \n",
      "    192         self._forward_input(allow_stdin)\n",
      "    193 \n",
      "    194         reply_content = {}\n",
      "    195         try:\n",
      "--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "        res = undefined\n",
      "        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n",
      "        code = 'all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")'\n",
      "        store_history = True\n",
      "        silent = False\n",
      "    197         finally:\n",
      "    198             self._restore_input()\n",
      "    199 \n",
      "    200         if res.error_before_exec is not None:\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")',), **kwargs={'silent': False, 'store_history': True})\n",
      "    528             )\n",
      "    529         self.payload_manager.write_payload(payload)\n",
      "    530 \n",
      "    531     def run_cell(self, *args, **kwargs):\n",
      "    532         self._last_traceback = None\n",
      "--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n",
      "        args = ('all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")',)\n",
      "        kwargs = {'silent': False, 'store_history': True}\n",
      "    534 \n",
      "    535     def _showtraceback(self, etype, evalue, stb):\n",
      "    536         # try to preserve ordering of tracebacks and print statements\n",
      "    537         sys.stdout.flush()\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")', store_history=True, silent=False, shell_futures=True)\n",
      "   2723                 self.displayhook.exec_result = result\n",
      "   2724 \n",
      "   2725                 # Execute the user code\n",
      "   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n",
      "   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n",
      "-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n",
      "        interactivity = 'last_expr'\n",
      "        compiler = <IPython.core.compilerop.CachingCompiler object>\n",
      "   2729                 \n",
      "   2730                 self.last_execution_succeeded = not has_raised\n",
      "   2731                 self.last_execution_result = result\n",
      "   2732 \n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.For object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-4-a25bd94358df>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1a21db125f8, executio..._before_exec=None error_in_exec=None result=None>)\n",
      "   2845 \n",
      "   2846         try:\n",
      "   2847             for i, node in enumerate(to_run_exec):\n",
      "   2848                 mod = ast.Module([node])\n",
      "   2849                 code = compiler(mod, cell_name, \"exec\")\n",
      "-> 2850                 if self.run_code(code, result):\n",
      "        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n",
      "        code = <code object <module> at 0x000001A21DB0DD20, file \"<ipython-input-4-a25bd94358df>\", line 8>\n",
      "        result = <ExecutionResult object at 1a21db125f8, executio..._before_exec=None error_in_exec=None result=None>\n",
      "   2851                     return True\n",
      "   2852 \n",
      "   2853             for i, node in enumerate(to_run_interactive):\n",
      "   2854                 mod = ast.Interactive([node])\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001A21DB0DD20, file \"<ipython-input-4-a25bd94358df>\", line 8>, result=<ExecutionResult object at 1a21db125f8, executio..._before_exec=None error_in_exec=None result=None>)\n",
      "   2905         outflag = True  # happens in more places, so it's easier as default\n",
      "   2906         try:\n",
      "   2907             try:\n",
      "   2908                 self.hooks.pre_run_code_hook()\n",
      "   2909                 #rprint('Running code', repr(code_obj)) # dbg\n",
      "-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "        code_obj = <code object <module> at 0x000001A21DB0DD20, file \"<ipython-input-4-a25bd94358df>\", line 8>\n",
      "        self.user_global_ns = {'ERPCovariances': <class 'pyriemann.estimation.ERPCovariances'>, 'Epochs': <class 'mne.epochs.Epochs'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"# BUILT-IN\\nimport os,sys\\nimport math\\nfrom collec..._ipython().run_line_magic('matplotlib', 'inline')\", 'the_folder_path = \"../data/p300_speller\" # relat...gentSpace(metric=\\'riemann\\'),LogisticRegression())', 'def estimatorParamsDict():\\n    \"\"\"# get all para...redictor_{}.pkl\\'.format(datetime.datetime.now()))', 'all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")'], 'LDA': <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MDM': <class 'pyriemann.classification.MDM'>, 'OrderedDict': <class 'collections.OrderedDict'>, 'Out': {}, 'RawArray': <class 'mne.io.array.array.RawArray'>, ...}\n",
      "        self.user_ns = {'ERPCovariances': <class 'pyriemann.estimation.ERPCovariances'>, 'Epochs': <class 'mne.epochs.Epochs'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"# BUILT-IN\\nimport os,sys\\nimport math\\nfrom collec..._ipython().run_line_magic('matplotlib', 'inline')\", 'the_folder_path = \"../data/p300_speller\" # relat...gentSpace(metric=\\'riemann\\'),LogisticRegression())', 'def estimatorParamsDict():\\n    \"\"\"# get all para...redictor_{}.pkl\\'.format(datetime.datetime.now()))', 'all_results =  pd.DataFrame({\\'Temp\\' : []})\\nraw =...itional_path,\"AUC.png\"),dpi = 800,format = \"png\")'], 'LDA': <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MDM': <class 'pyriemann.classification.MDM'>, 'OrderedDict': <class 'collections.OrderedDict'>, 'Out': {}, 'RawArray': <class 'mne.io.array.array.RawArray'>, ...}\n",
      "   2911             finally:\n",
      "   2912                 # Reset our crash handler in place\n",
      "   2913                 sys.excepthook = old_excepthook\n",
      "   2914         except SystemExit as e:\n",
      "\n",
      "...........................................................................\n",
      "D:\\Dropbox (Personal)\\XXXX_PERS_Git\\reproducibility\\code\\<ipython-input-4-a25bd94358df> in <module>()\n",
      "     70                 #params = []\n",
      "     71                 # cross validation AUC score by classifier\n",
      "     72                 for m in clfs:\n",
      "     73                     #clf = GridSearchCV(clfs[m], grid_params)\n",
      "     74                     #clf.fit(train, y_train)\n",
      "---> 75                     res = cross_val_score(clfs[m], X, y==2, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
      "     76                     auc.extend(res)\n",
      "     77                     methods.extend([m]*len(res))\n",
      "     78                 the_best_score = max(auc)\n",
      "     79                 the_best_method = methods[auc.index(the_best_score)]\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_val_score(estimator=Pipeline(memory=None,\n",
      "     steps=[('erpcovarianc...0.0001,\n",
      "          verbose=0, warm_start=False))]), X=array([[[ -5622.37988281,  -5626.40332031,  -562...66.53027344, -13866.53027344, -13866.53027344]]]), y=array([ True, False,  True, ...,  True,  True,  True]), groups=None, scoring='roc_auc', cv=StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=0.25,\n",
      "            train_size=None), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n",
      "    337     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n",
      "    338                                 scoring={'score': scorer}, cv=cv,\n",
      "    339                                 return_train_score=False,\n",
      "    340                                 n_jobs=n_jobs, verbose=verbose,\n",
      "    341                                 fit_params=fit_params,\n",
      "--> 342                                 pre_dispatch=pre_dispatch)\n",
      "        pre_dispatch = '2*n_jobs'\n",
      "    343     return cv_results['test_score']\n",
      "    344 \n",
      "    345 \n",
      "    346 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_validate(estimator=Pipeline(memory=None,\n",
      "     steps=[('erpcovarianc...0.0001,\n",
      "          verbose=0, warm_start=False))]), X=array([[[ -5622.37988281,  -5626.40332031,  -562...66.53027344, -13866.53027344, -13866.53027344]]]), y=array([ True, False,  True, ...,  True,  True,  True]), groups=None, scoring={'score': make_scorer(roc_auc_score, needs_threshold=True)}, cv=StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=0.25,\n",
      "            train_size=None), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)\n",
      "    201     scores = parallel(\n",
      "    202         delayed(_fit_and_score)(\n",
      "    203             clone(estimator), X, y, scorers, train, test, verbose, None,\n",
      "    204             fit_params, return_train_score=return_train_score,\n",
      "    205             return_times=True)\n",
      "--> 206         for train, test in cv.split(X, y, groups))\n",
      "        cv.split = <bound method StratifiedShuffleSplit.split of St...42, test_size=0.25,\n",
      "            train_size=None)>\n",
      "        X = array([[[ -5622.37988281,  -5626.40332031,  -562...66.53027344, -13866.53027344, -13866.53027344]]])\n",
      "        y = array([ True, False,  True, ...,  True,  True,  True])\n",
      "        groups = None\n",
      "    207 \n",
      "    208     if return_train_score:\n",
      "    209         train_scores, test_scores, fit_times, score_times = zip(*scores)\n",
      "    210         train_scores = _aggregate_score_dicts(train_scores)\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n",
      "    784             if pre_dispatch == \"all\" or n_jobs == 1:\n",
      "    785                 # The iterable was consumed all at once by the above for loop.\n",
      "    786                 # No need to wait for async callbacks to trigger to\n",
      "    787                 # consumption.\n",
      "    788                 self._iterating = False\n",
      "--> 789             self.retrieve()\n",
      "        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n",
      "    790             # Make sure that we get a last message telling us we are done\n",
      "    791             elapsed_time = time.time() - self._start_time\n",
      "    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n",
      "    793                         (len(self._output), len(self._output),\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Sub-process traceback:\n",
      "---------------------------------------------------------------------------\n",
      "ValueError                                         Tue Jul  2 04:47:58 2019\n",
      "PID: 16936        Python 3.5.4: c:\\users\\pierr\\python354\\scripts\\python.exe\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n",
      "     steps=[('erpcovarianc...0.0001,\n",
      "          verbose=0, warm_start=False))]), memmap([[[ -5622.37988281,  -5626.40332031,  -56...66.53027344, -13866.53027344, -13866.53027344]]]), array([ True, False,  True, ...,  True,  True,  True]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([43554, 24011,  5991, ..., 45013,  1390, 27279], dtype=int64), array([46708, 43502, 24089, ...,  8734, 42815, 32929], dtype=int64), 0, None, None), {'return_times': True, 'return_train_score': False})]\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        func = <function _fit_and_score>\n",
      "        args = (Pipeline(memory=None,\n",
      "     steps=[('erpcovarianc...0.0001,\n",
      "          verbose=0, warm_start=False))]), memmap([[[ -5622.37988281,  -5626.40332031,  -56...66.53027344, -13866.53027344, -13866.53027344]]]), array([ True, False,  True, ...,  True,  True,  True]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([43554, 24011,  5991, ..., 45013,  1390, 27279], dtype=int64), array([46708, 43502, 24089, ...,  8734, 42815, 32929], dtype=int64), 0, None, None)\n",
      "        kwargs = {'return_times': True, 'return_train_score': False}\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n",
      "     steps=[('erpcovarianc...0.0001,\n",
      "          verbose=0, warm_start=False))]), X=memmap([[[ -5622.37988281,  -5626.40332031,  -56...66.53027344, -13866.53027344, -13866.53027344]]]), y=array([ True, False,  True, ...,  True,  True,  True]), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([43554, 24011,  5991, ..., 45013,  1390, 27279], dtype=int64), test=array([46708, 43502, 24089, ...,  8734, 42815, 32929], dtype=int64), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n",
      "    453 \n",
      "    454     try:\n",
      "    455         if y_train is None:\n",
      "    456             estimator.fit(X_train, **fit_params)\n",
      "    457         else:\n",
      "--> 458             estimator.fit(X_train, y_train, **fit_params)\n",
      "        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n",
      "          verbose=0, warm_start=False))])>\n",
      "        X_train = memmap([[[ -74826.8671875 ,  -74826.8671875 ,  -....796875  , -101992.796875  , -101992.796875  ]]])\n",
      "        y_train = array([ True, False,  True, ...,  True,  True,  True])\n",
      "        fit_params = {}\n",
      "    459 \n",
      "    460     except Exception as e:\n",
      "    461         # Note fit time as time until error\n",
      "    462         fit_time = time.time() - start_time\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n",
      "     steps=[('erpcovarianc...0.0001,\n",
      "          verbose=0, warm_start=False))]), X=memmap([[[ -74826.8671875 ,  -74826.8671875 ,  -....796875  , -101992.796875  , -101992.796875  ]]]), y=array([ True, False,  True, ...,  True,  True,  True]), **fit_params={})\n",
      "    243         Returns\n",
      "    244         -------\n",
      "    245         self : Pipeline\n",
      "    246             This estimator\n",
      "    247         \"\"\"\n",
      "--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n",
      "        Xt = undefined\n",
      "        fit_params = {}\n",
      "        self._fit = <bound method Pipeline._fit of Pipeline(memory=N....0001,\n",
      "          verbose=0, warm_start=False))])>\n",
      "        X = memmap([[[ -74826.8671875 ,  -74826.8671875 ,  -....796875  , -101992.796875  , -101992.796875  ]]])\n",
      "        y = array([ True, False,  True, ...,  True,  True,  True])\n",
      "    249         if self._final_estimator is not None:\n",
      "    250             self._final_estimator.fit(Xt, y, **fit_params)\n",
      "    251         return self\n",
      "    252 \n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n",
      "     steps=[('erpcovarianc...0.0001,\n",
      "          verbose=0, warm_start=False))]), X=memmap([[[ -74826.8671875 ,  -74826.8671875 ,  -....796875  , -101992.796875  , -101992.796875  ]]]), y=array([ True, False,  True, ...,  True,  True,  True]), **fit_params={})\n",
      "    208                 else:\n",
      "    209                     cloned_transformer = clone(transformer)\n",
      "    210                 # Fit or load from cache the current transfomer\n",
      "    211                 Xt, fitted_transformer = fit_transform_one_cached(\n",
      "    212                     cloned_transformer, None, Xt, y,\n",
      "--> 213                     **fit_params_steps[name])\n",
      "        fit_params_steps = {'erpcovariances': {}, 'logisticregression': {}, 'tangentspace': {}}\n",
      "        name = 'tangentspace'\n",
      "    214                 # Replace the transformer of the step with the fitted\n",
      "    215                 # transformer. This is necessary when loading the transformer\n",
      "    216                 # from the cache.\n",
      "    217                 self.steps[step_idx] = (name, fitted_transformer)\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x0000016E91AEF598>), *args=(TangentSpace(metric='riemann', tsupdate=False), None, array([[[ 2.45919025e+00,  3.27597213e+00,  3.25...7226459e+01,  5.07149557e+01,  5.75581231e+01]]]), array([ True, False,  True, ...,  True,  True,  True])), **kwargs={})\n",
      "    357     # Should be a light as possible (for speed)\n",
      "    358     def __init__(self, func):\n",
      "    359         self.func = func\n",
      "    360 \n",
      "    361     def __call__(self, *args, **kwargs):\n",
      "--> 362         return self.func(*args, **kwargs)\n",
      "        self.func = <function _fit_transform_one>\n",
      "        args = (TangentSpace(metric='riemann', tsupdate=False), None, array([[[ 2.45919025e+00,  3.27597213e+00,  3.25...7226459e+01,  5.07149557e+01,  5.75581231e+01]]]), array([ True, False,  True, ...,  True,  True,  True]))\n",
      "        kwargs = {}\n",
      "    363 \n",
      "    364     def call_and_shelve(self, *args, **kwargs):\n",
      "    365         return NotMemorizedResult(self.func(*args, **kwargs))\n",
      "    366 \n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=TangentSpace(metric='riemann', tsupdate=False), weight=None, X=array([[[ 2.45919025e+00,  3.27597213e+00,  3.25...7226459e+01,  5.07149557e+01,  5.75581231e+01]]]), y=array([ True, False,  True, ...,  True,  True,  True]), **fit_params={})\n",
      "    576 \n",
      "    577 \n",
      "    578 def _fit_transform_one(transformer, weight, X, y,\n",
      "    579                        **fit_params):\n",
      "    580     if hasattr(transformer, 'fit_transform'):\n",
      "--> 581         res = transformer.fit_transform(X, y, **fit_params)\n",
      "        res = undefined\n",
      "        transformer.fit_transform = <bound method TangentSpace.fit_transform of TangentSpace(metric='riemann', tsupdate=False)>\n",
      "        X = array([[[ 2.45919025e+00,  3.27597213e+00,  3.25...7226459e+01,  5.07149557e+01,  5.75581231e+01]]])\n",
      "        y = array([ True, False,  True, ...,  True,  True,  True])\n",
      "        fit_params = {}\n",
      "    582     else:\n",
      "    583         res = transformer.fit(X, y, **fit_params).transform(X)\n",
      "    584     # if we have a weight for this transformer, multiply output\n",
      "    585     if weight is None:\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\pyriemann\\tangentspace.py in fit_transform(self=TangentSpace(metric='riemann', tsupdate=False), X=array([[[ 2.45919025e+00,  3.27597213e+00,  3.25...7226459e+01,  5.07149557e+01,  5.75581231e+01]]]), y=array([ True, False,  True, ...,  True,  True,  True]), sample_weight=None)\n",
      "    163             the tangent space projection of the matrices.\n",
      "    164         \"\"\"\n",
      "    165         # compute mean covariance\n",
      "    166         self._check_reference_points(X)\n",
      "    167         self.reference_ = mean_covariance(X, metric=self.metric,\n",
      "--> 168                                           sample_weight=sample_weight)\n",
      "        sample_weight = None\n",
      "    169         return tangent_space(X, self.reference_)\n",
      "    170 \n",
      "    171     def inverse_transform(self, X, y=None):\n",
      "    172         \"\"\"Inverse transform.\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\pyriemann\\utils\\mean.py in mean_covariance(covmats=array([[[ 2.45919025e+00,  3.27597213e+00,  3.25...7226459e+01,  5.07149557e+01,  5.75581231e+01]]]), metric='riemann', sample_weight=None, *args=())\n",
      "    327 \n",
      "    328     \"\"\"\n",
      "    329     if callable(metric):\n",
      "    330         C = metric(covmats, sample_weight=sample_weight, *args)\n",
      "    331     else:\n",
      "--> 332         C = mean_methods[metric](covmats, sample_weight=sample_weight, *args)\n",
      "        C = undefined\n",
      "        metric = 'riemann'\n",
      "        covmats = array([[[ 2.45919025e+00,  3.27597213e+00,  3.25...7226459e+01,  5.07149557e+01,  5.75581231e+01]]])\n",
      "        sample_weight = None\n",
      "        args = ()\n",
      "    333     return C\n",
      "    334 \n",
      "    335 mean_methods = {'riemann': mean_riemann,\n",
      "    336                 'logeuclid': mean_logeuclid,\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\pyriemann\\utils\\mean.py in mean_riemann(covmats=array([[[ 2.45919025e+00,  3.27597213e+00,  3.25...7226459e+01,  5.07149557e+01,  5.75581231e+01]]]), tol=1e-08, maxiter=50, init=None, sample_weight=array([2.65139463e-05, 2.65139463e-05, 2.6513946... 2.65139463e-05, 2.65139463e-05, 2.65139463e-05]))\n",
      "     60             tmp = numpy.dot(numpy.dot(Cm12, covmats[index, :, :]), Cm12)\n",
      "     61             J += sample_weight[index] * logm(tmp)\n",
      "     62 \n",
      "     63         crit = numpy.linalg.norm(J, ord='fro')\n",
      "     64         h = nu * crit\n",
      "---> 65         C = numpy.dot(numpy.dot(C12, expm(nu * J)), C12)\n",
      "        C = array([[ 2.45919025,  3.27597213,  3.25945182, .... 47.33798977,\n",
      "        41.68998419, 92.276785  ]])\n",
      "        C12 = array([[0.41639577, 0.27252356, 0.34065621, ...,....., 1.4018853 , 1.2178285 ,\n",
      "        7.72646112]])\n",
      "        nu = 1.0\n",
      "        J = array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "    ...an],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]])\n",
      "     66         if h < tau:\n",
      "     67             nu = 0.95 * nu\n",
      "     68             tau = h\n",
      "     69         else:\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\pyriemann\\utils\\base.py in expm(Ci=array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "    ...an],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]]))\n",
      "     57 \n",
      "     58     :param Ci: the coavriance matrix\n",
      "     59     :returns: the matrix exponential\n",
      "     60 \n",
      "     61     \"\"\"\n",
      "---> 62     return _matrix_operator(Ci, numpy.exp)\n",
      "        Ci = array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "    ...an],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]])\n",
      "     63 \n",
      "     64 \n",
      "     65 def invsqrtm(Ci):\n",
      "     66     \"\"\"Return the inverse matrix square root of a covariance matrix defined by :\n",
      "\n",
      "...........................................................................\n",
      "c:\\users\\pierr\\python354\\lib\\site-packages\\pyriemann\\utils\\base.py in _matrix_operator(Ci=array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "    ...an],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]]), operator=<ufunc 'exp'>)\n",
      "      5 \n",
      "      6 \n",
      "      7 def _matrix_operator(Ci, operator):\n",
      "      8     \"\"\"matrix equivalent of an operator.\"\"\"\n",
      "      9     if Ci.dtype.char in typecodes['AllFloat'] and not numpy.isfinite(Ci).all():\n",
      "---> 10         raise ValueError(\"Covariance matrices must be positive definite. Add regularization to avoid this error.\")\n",
      "     11     eigvals, eigvects = scipy.linalg.eigh(Ci, check_finite=False)\n",
      "     12     eigvals = numpy.diag(operator(eigvals))\n",
      "     13     Out = numpy.dot(numpy.dot(eigvects, eigvals), eigvects.T)\n",
      "     14     return Out\n",
      "\n",
      "ValueError: Covariance matrices must be positive definite. Add regularization to avoid this error.\n",
      "___________________________________________________________________________\n",
      "device:openbci_v207 user:compmonks dir:['session_000', 'session_001', 'session_002', 'session_003', 'session_004', 'session_005', 'session_006', 'session_007', 'session_008', 'session_009', 'session_010', 'session_011', 'session_012', 'session_013', 'session_014'] session dir:session_014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session_num: 15\n",
      "files: ['compmonks_T2_FEEDBACK_2019-6-29_9-13-53-861000.hdf5', 'compmonks_T2_OPENBCI-Cytonv207_2019-6-29_9-20-49-622419.hdf5']\n",
      "Creating RawArray with float64 data, n_channels=17, n_times=47301\n",
      "    Range : 0 ... 47300 =      0.000 ...   378.400 secs\n",
      "Ready.\n",
      "159174 events found\n",
      "Event IDs: [1 2]\n"
     ]
    }
   ],
   "source": [
    "all_results =  pd.DataFrame({'Temp' : []})\n",
    "raw = []\n",
    "session_num = 0\n",
    "the_training_path = os.path.join(the_folder_path,the_device,the_user,\"training\")\n",
    "the_additional_path = os.path.join(the_folder_path,the_device,the_user,\"additional\")\n",
    "all_sessions_data_path = list(os.walk(the_training_path)) + list(os.walk(the_additional_path))\n",
    "#\n",
    "for root, subdirs, files in all_sessions_data_path:\n",
    "    for dirs in subdirs:\n",
    "        print(\"device:{} user:{} dir:{} session dir:{}\".format(the_device,the_user,subdirs,dirs))\n",
    "        file_list = [fn for fn in os.listdir(os.path.join(root,dirs)) if fn.endswith(\"hdf5\")]\n",
    "        if len(file_list) == 2:\n",
    "            try:\n",
    "                print(\"session_num: {}\".format(session_num))\n",
    "                print(\"files: {}\".format(file_list))\n",
    "                if \"FEEDBACK\" in file_list[0]:\n",
    "                    dataF = pd.read_hdf(os.path.join(root,dirs,file_list[0]),'data')\n",
    "                    dataA = pd.read_hdf(os.path.join(root,dirs,file_list[1]),'EEG')\n",
    "                else:\n",
    "                    dataF = pd.read_hdf(os.path.join(root,dirs,file_list[1]),'data')\n",
    "                    dataA = pd.read_hdf(os.path.join(root,dirs,file_list[0]),'EEG')\n",
    "                #\n",
    "                dataA['Stim'] = np.nan\n",
    "                prev_marker = 0\n",
    "                for index,row in dataA.iterrows():\n",
    "                    new_marker = dataF.iloc[dataF.index.get_loc(pd.to_datetime(index),method='nearest')]['marker'].astype(int)\n",
    "                    if prev_marker == 0:\n",
    "                        if new_marker != 0:\n",
    "                            row['Stim'] = new_marker\n",
    "                            prev_marker = new_marker\n",
    "                        else:\n",
    "                            row['Stim'] = 0\n",
    "                    else:\n",
    "                        row['Stim'] = 0\n",
    "                        prev_marker = new_marker\n",
    "\n",
    "                channel_names = list(dataA.keys())\n",
    "                # temporary fix on possibly erroneous channel labelling on some of the former data\n",
    "                for _it,_ch in enumerate(channel_names):\n",
    "                    if _ch == \"P2\":\n",
    "                        channel_names[_it] = \"O2\"\n",
    "                #\n",
    "                channel_types = ['eeg'] * (len(list(dataA.keys()))-1) + ['stim']\n",
    "                the_data = dataA.values[:].T\n",
    "                the_data[:-1] *= 1e-6 if the_units == \"uVolts\" else 1\n",
    "                info = create_info(ch_names = channel_names, \n",
    "                                   ch_types = channel_types,\n",
    "                                   sfreq = the_freq, \n",
    "                                   montage = the_montage)\n",
    "                raw.append(RawArray(data = the_data, info = info))\n",
    "                the_raw = concatenate_raws(raw)\n",
    "                the_events = find_events(the_raw)\n",
    "                the_epochs = Epochs(the_raw,\n",
    "                                    events = the_events, \n",
    "                                    event_id = the_markers,\n",
    "                                    tmin = -0.1, tmax = 0.7,\n",
    "                                    baseline = None,\n",
    "                                    reject = {'eeg': 75e-6},\n",
    "                                    preload = True,\n",
    "                                    verbose = False,\n",
    "                                    picks = list(range(len(channel_names)-1))\n",
    "                                   )\n",
    "                #\n",
    "                the_epochs.pick_types(eeg=True)\n",
    "                X = the_epochs.get_data() * 1e6\n",
    "                y = the_epochs.events[:, -1]\n",
    "                cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "                auc = []\n",
    "                methods = []\n",
    "                #params = []\n",
    "                # cross validation AUC score by classifier\n",
    "                for m in clfs:\n",
    "                    #clf = GridSearchCV(clfs[m], grid_params)\n",
    "                    #clf.fit(train, y_train)\n",
    "                    res = cross_val_score(clfs[m], X, y==2, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "                    auc.extend(res)\n",
    "                    methods.extend([m]*len(res))\n",
    "                the_best_score = max(auc)\n",
    "                the_best_method = methods[auc.index(the_best_score)]\n",
    "                print(\"The best predictor is: {} score:{}\".format(the_best_method, the_best_score))\n",
    "                # plot\n",
    "                results = pd.DataFrame(data=auc, columns=['AUC'])\n",
    "                results['Method'] = methods\n",
    "                results['session_num'] = session_num\n",
    "                if all_results.empty:\n",
    "                    palette = sns.color_palette(categorical_color_palette, len(results))\n",
    "                    all_results = results.copy()\n",
    "                else:\n",
    "                    all_results = pd.concat([all_results, results], ignore_index=True, sort=False)\n",
    "                session_num +=1\n",
    "            except Exception as e:\n",
    "                print(\"ERROR: {}\".format(e))\n",
    "                pass\n",
    "# train and save best predictor with all data\n",
    "train_save(clfs[the_best_method], X, y)\n",
    "\n",
    "# plotting the accuracy comparison over sessions\n",
    "lp = sns.lineplot(x='session_num', y='AUC', hue='Method', data=all_results)\n",
    "lp.legend(loc='center right', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.savefig(os.path.join(the_additional_path,\"AUC.png\"),dpi = 800,format = \"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
